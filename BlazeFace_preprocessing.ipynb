{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "def extract_mouth_wo_background(image_path,output_path):\n",
        "    # Load the image using OpenCV\n",
        "    frame = cv2.imread(image_path)\n",
        "    \n",
        "    # Initialize MediaPipe Face Mesh\n",
        "    face_mesh = mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=True,\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5)\n",
        "    \n",
        "    # Process the image using MediaPipe Face Mesh\n",
        "    results = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    black = np.zeros(frame.shape, np.uint8)\n",
        "    mouth=[0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270,308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415]\n",
        "    \n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image=black,\n",
        "                landmark_list=face_landmarks,\n",
        "                connections=mp_face_mesh.FACEMESH_LIPS,\n",
        "                landmark_drawing_spec=None,\n",
        "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
        "            black = black[..., 0:1]\n",
        "            mouth_landmarks = [face_landmarks.landmark[i] for i in mouth]\n",
        "            # Find the bounding box around the mouth\n",
        "            x_values = [point.x * frame.shape[1] for point in mouth_landmarks]\n",
        "            y_values = [point.y * frame.shape[0] for point in mouth_landmarks]\n",
        "            xmin = int(min(x_values))-10\n",
        "            xmax = int(max(x_values))+10\n",
        "            ymin = int(min(y_values))-10\n",
        "            ymax = int(max(y_values))+10\n",
        "\n",
        "            # Crop the mouth region from the image\n",
        "            cropped_mouth = black[ymin:ymax, xmin:xmax]\n",
        "\n",
        "    # results = cropped_mouth[..., 0:1]\n",
        "    face_mesh.close()\n",
        "    \n",
        "    \n",
        "    cv2.imwrite(output_path, cropped_mouth)\n",
        "    # frame = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # print(frame.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "def extract_mouth_with_background(image_path,output_path):\n",
        "    # Load the image using OpenCV\n",
        "    frame = cv2.imread(image_path)\n",
        "    \n",
        "    # Initialize MediaPipe Face Mesh\n",
        "    face_mesh = mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=True,\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5)\n",
        "    \n",
        "    # Process the image using MediaPipe Face Mesh\n",
        "    image=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(image)\n",
        "    mouth=[0, 13, 14, 17, 37, 39, 40, 61, 78, 80, 81, 82, 84, 87, 88, 91, 95, 146, 178, 181, 185, 191, 267, 269, 270,308, 310, 311, 312, 314, 317, 318, 321, 324, 375, 402, 405, 409, 415]\n",
        "    \n",
        "    \n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image=frame,\n",
        "                landmark_list=face_landmarks,\n",
        "                connections=mp_face_mesh.FACEMESH_LIPS,\n",
        "                landmark_drawing_spec=None,\n",
        "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
        "            frame=frame[...,0:1]\n",
        "            mouth_landmarks = [face_landmarks.landmark[i] for i in mouth]\n",
        "            # Find the bounding box around the mouth\n",
        "            x_values = [point.x * frame.shape[1] for point in mouth_landmarks]\n",
        "            y_values = [point.y * frame.shape[0] for point in mouth_landmarks]\n",
        "            xmin = int(min(x_values))-10\n",
        "            xmax = int(max(x_values))+10\n",
        "            ymin = int(min(y_values))-10\n",
        "            ymax = int(max(y_values))+10\n",
        "\n",
        "            # Crop the mouth region from the image\n",
        "            cropped_mouth = frame[ymin:ymax, xmin:xmax]\n",
        "\n",
        "    \n",
        "    face_mesh.close()\n",
        "    \n",
        "    cv2.imwrite(output_path, cropped_mouth)\n",
        "    # frame = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # print(frame.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#step 1 : input image path 알아서 설정\n",
        "image_path = \"/Users/jihoojung/Desktop/snu/5-2/vision/project/data/F08/words/01/01/color_006.jpg\"\n",
        "#step 2 : output path 알아서 설정 \n",
        "output_path=\"results/results.jpg\"\n",
        "# step 3 : lip line만 얻고 싶으면, extract_mouth_wo_background function 이용, \n",
        "# input 이미지 위에 lip line 따진 거 얻고 싶으면, extract_mouth_with_background function 이용\n",
        "# 실행하면 output_path에 이미지 생성 완료됨\n",
        "extract_mouth_with_background(image_path,output_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lips",
      "language": "python",
      "name": "lips"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
